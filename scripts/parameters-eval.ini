[train_param]
mode = evaluate

n_epochs = 100
n_iters = 20
plot_every = 10
save_every = 20
print_every = 10

[model_param]
hidden_size = 256
n_layers = 2
dropout_p = 0.1
learning_rate = 0.001
teacher_forcing_ratio = 0.8
attn_mode = general
max_len = 100

[data_utils_param]
lang_in = sent
lang_out = ner
output_model_path = /home/liah/ner/seq2seq_for_ner/src/model/alldata
#output_model_path = /home/liah/ner/seq2seq_for_ner/src/model/test_batch

lang_obj_file = /home/liah/ner/seq2seq_for_ner/src/data/obj_sent_ner

encoder_path = /home/liah/ner/seq2seq_for_ner/src/model/alldata/100-encoder.pt

decoder_path = /home/liah/ner/seq2seq_for_ner/src/model/alldata/100-decoder.pt