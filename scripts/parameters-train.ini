[train_param]
###
tune_hyperparam = True
mode = train
n_epochs = 200
n_iters = 20
plot_every = 10
save_every = 1
print_every = 1
#note: evaluate at least after one model is saved
evaluate_every = 1
patience = 30
save_best_epoch = True
main_eval_method = sklearn
###
step = 1
#if resume, use pre-trained model, otherwise reinit model from start
resume = False
#if add_class, change decoder output space
add_class = False

[model_param]
#seq2seq or bilstm
###
nn_model = seq2seq
batch_size = 32
###
clip = 5
use_pretrained_word_embedding = True
use_char_embedding = True
###
char_emb_size = 25
hidden_size = 128
n_layers = 1
n_layers_encoder = 1
n_layers_decoder = 1
#dropout_p = 0.5
dropout_p = 0.5
#learning_rate = 0.001
learning_rate = 0.005

teacher_forcing_ratio = 1
attn_mode = general
# ???
max_len = 100

[data_utils_param]
lang_in = sent
lang_out = ner

[file_path_param]
dataset_filepath = /home/liah/ner/seq2seq_for_ner/src/data/conll03-ner-loc-bioes/train1
#dataset_filepath = /home/liah/ner/seq2seq_for_ner/src/data/conll03-ner-loc/train2
# add /step1 and /step2 after
output_model_dir = /home/liah/ner/seq2seq_for_ner/src/model/loc-seq2seq-char-bioes-hyperparam
pred_output_dir = /home/liah/ner/seq2seq_for_ner/src/result/loc-seq2seq-char-bioes-hyperparam
# none or baseline_a , baseline_b
baseline_folder = none
lang_obj_file_name = obj_sent_ner_step1
#output_model_filepath = /home/liah/ner/seq2seq_for_ner/src/model/test_bilstm_
#pred_output_folder = /home/liah/ner/seq2seq_for_ner/src/result/test_bilstm_

conll_filepath = /home/liah/ner/seq2seq_for_ner/src/scripts_eg/conlleval

embedding_filepath = /home/liah/word_vectors/eng/glove.6B.100d.txt

#seems not to be used in train
encoder_path = /home/liah/ner/seq2seq_for_ner/src/model/loc-seq2seq-char-bioes-hyperparam/step1/best-encoder.pt
decoder_path = /home/liah/ner/seq2seq_for_ner/src/model/loc-seq2seq-char-bioes-hyperparam/step1/best-decoder.pt